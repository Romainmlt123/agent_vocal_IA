"""
User Interface for Agent Vocal IA using Gradio.

Provides an interactive web interface for the vocal tutoring system.
"""

import logging
import os
import sys
from pathlib import Path

import gradio as gr

# Add parent directory to path to import src modules
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.orchestrator import VocalTutorOrchestrator
from src.conversation_manager import ConversationManager
from src.utils import get_config, setup_logging


class VocalTutorUI:
    """Gradio UI for Vocal Tutor."""
    
    def __init__(self, config_path: str = "config.yaml"):
        """
        Initialize UI.
        
        Args:
            config_path: Path to configuration file
        """
        # Setup logging
        setup_logging(level='INFO')
        self.logger = logging.getLogger(__name__)
        
        # Load config
        self.config = get_config(config_path)
        
        # Initialize orchestrator (lazy)
        self.orchestrator: VocalTutorOrchestrator = None
        
        # Initialize conversation manager (lazy)
        self.conversation_manager: ConversationManager = None
        
        # Conversation state
        self.conversation_history = []
        self.conversation_active = False
        
        # UI configuration
        self.title = self.config.get('ui.title', 'üéì Agent Vocal IA - Tuteur √âducatif')
        self.description = self.config.get('ui.description', 
                                          'Assistant vocal local pour l\'apprentissage (100% offline)')
        self.theme = self.config.get('ui.theme', 'soft')
        
        self.logger.info("Vocal Tutor UI initialized")
    
    def _get_orchestrator(self) -> VocalTutorOrchestrator:
        """Get or create orchestrator instance."""
        if self.orchestrator is None:
            self.logger.info("Loading orchestrator...")
            self.orchestrator = VocalTutorOrchestrator(self.config)
        return self.orchestrator
    
    def _get_conversation_manager(self) -> ConversationManager:
        """Get or create conversation manager instance."""
        if self.conversation_manager is None:
            self.logger.info("Loading conversation manager...")
            orchestrator = self._get_orchestrator()
            self.conversation_manager = ConversationManager(self.config, orchestrator)
        return self.conversation_manager
    
    def process_audio_input(
        self,
        audio_input,
        subject: str,
        auto_detect: bool
    ):
        """
        Process audio input from microphone.
        
        Args:
            audio_input: Audio from Gradio microphone component (tuple of sample_rate, audio_data)
            subject: Selected subject
            auto_detect: Whether to auto-detect subject
            
        Returns:
            Tuple of (transcript, response, sources_text, audio_output, status)
        """
        try:
            self.logger.info("Processing audio input...")
            
            if audio_input is None:
                return ("", "", "", None, "‚ùå Aucun audio fourni")
            
            # Save audio to temporary file
            import tempfile
            import soundfile as sf
            
            sample_rate, audio_data = audio_input
            
            with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
                tmp_path = tmp.name
                sf.write(tmp_path, audio_data, sample_rate)
            
            # Get orchestrator
            orchestrator = self._get_orchestrator()
            
            # Set subject if not auto-detecting
            if not auto_detect and subject:
                orchestrator.set_subject(subject)
            
            # Process
            results = orchestrator.process_audio_file(
                tmp_path,
                subject=None if auto_detect else subject
            )
            
            # Clean up temp file
            if os.path.exists(tmp_path):
                os.remove(tmp_path)
            
            # Extract results
            if results.get('success'):
                transcript = results.get('transcript', '')
                response = results.get('response', '')
                sources = results.get('sources', [])
                audio_output = results.get('audio_output')
                detected_subject = results.get('subject', '')
                
                # Format sources
                sources_text = self._format_sources(sources)
                
                # Status message
                status = f"‚úÖ Succ√®s! Mati√®re: {detected_subject}"
                
                return (transcript, response, sources_text, audio_output, status)
            else:
                error = results.get('error', 'Erreur inconnue')
                return ("", "", "", None, f"‚ùå Erreur: {error}")
                
        except Exception as e:
            self.logger.error(f"Error processing audio: {e}", exc_info=True)
            return ("", "", "", None, f"‚ùå Erreur: {str(e)}")
    
    def process_text_input(
        self,
        text: str,
        subject: str,
        auto_detect: bool,
        generate_audio: bool
    ):
        """
        Process text input.
        
        Args:
            text: Text question
            subject: Selected subject
            auto_detect: Whether to auto-detect subject
            generate_audio: Whether to generate TTS audio
            
        Returns:
            Tuple of (response, sources_text, audio_output, status)
        """
        try:
            if not text or not text.strip():
                return ("", "", None, "‚ùå Veuillez saisir une question")
            
            self.logger.info(f"Processing text: {text[:50]}...")
            
            # Get orchestrator
            orchestrator = self._get_orchestrator()
            
            # Set subject if not auto-detecting
            if not auto_detect and subject:
                orchestrator.set_subject(subject)
            
            # Process
            results = orchestrator.process_text_question(
                text,
                subject=None if auto_detect else subject,
                generate_audio=generate_audio
            )
            
            # Extract results
            if results.get('success'):
                response = results.get('response', '')
                sources = results.get('sources', [])
                audio_output = results.get('audio_output') if generate_audio else None
                detected_subject = results.get('subject', '')
                
                # Format sources
                sources_text = self._format_sources(sources)
                
                # Status
                status = f"‚úÖ Succ√®s! Mati√®re: {detected_subject}"
                
                return (response, sources_text, audio_output, status)
            else:
                error = results.get('error', 'Erreur inconnue')
                return ("", "", None, f"‚ùå Erreur: {error}")
                
        except Exception as e:
            self.logger.error(f"Error processing text: {e}", exc_info=True)
            return ("", "", None, f"‚ùå Erreur: {str(e)}")
    
    def _format_sources(self, sources: list) -> str:
        """Format sources for display."""
        if not sources:
            return "Aucune source trouv√©e"
        
        lines = ["üìö Sources utilis√©es:\n"]
        for i, src in enumerate(sources, 1):
            filename = src.get('filename', 'Inconnu')
            score = src.get('score', 0)
            lines.append(f"{i}. {filename} (score: {score:.3f})")
        
        return "\n".join(lines)
    
    def toggle_conversation(
        self,
        current_state: bool,
        subject: str,
        auto_detect: bool
    ):
        """
        Toggle conversation mode on/off.
        
        Args:
            current_state: Current conversation state
            subject: Selected subject
            auto_detect: Whether to auto-detect subject
            
        Returns:
            Tuple of (new_state, button_text, button_variant, status_message, transcript, response)
        """
        try:
            if not current_state:
                # Start conversation
                self.logger.info("Starting continuous conversation...")
                
                # Get conversation manager
                conv_mgr = self._get_conversation_manager()
                
                # Set subject if not auto-detecting
                if not auto_detect and subject:
                    self._get_orchestrator().set_subject(subject)
                
                # Clear previous history for this session
                self.conversation_history = []
                
                # Start conversation
                conv_mgr.start_conversation()
                
                return (
                    True,  # new state
                    "üõë Arr√™ter la conversation",
                    "stop",
                    "üé§ Conversation active! Parlez naturellement, l'IA d√©tectera automatiquement quand vous avez fini de parler.",
                    "",  # transcript
                    ""   # response
                )
            
            else:
                # Stop conversation
                self.logger.info("Stopping continuous conversation...")
                
                conv_mgr = self._get_conversation_manager()
                conv_mgr.stop_conversation()
                
                return (
                    False,  # new state
                    "üé§ D√©marrer la conversation",
                    "primary",
                    "‚úÖ Conversation termin√©e. Cliquez pour recommencer.",
                    "",  # transcript
                    ""   # response
                )
        
        except Exception as e:
            self.logger.error(f"Error toggling conversation: {e}", exc_info=True)
            return (
                False,
                "üé§ D√©marrer la conversation",
                "primary",
                f"‚ùå Erreur: {str(e)}",
                "",
                ""
            )
    
    def poll_conversation_updates(self, is_active: bool):
        """
        Poll for conversation updates (for real-time display).
        
        Args:
            is_active: Whether conversation is active
            
        Returns:
            Tuple of (transcript, response, history, status)
        """
        if not is_active:
            return ("", "", self.get_conversation_history(), "")
        
        try:
            conv_mgr = self._get_conversation_manager()
            results = conv_mgr.get_latest_results()
            
            transcript = results.get('transcript', '')
            response = results.get('response', '')
            status = results.get('status', '')
            
            # Update history if we have new results
            if transcript and response:
                # Check if this is a new entry
                if not self.conversation_history or \
                   self.conversation_history[-1].get('user') != transcript:
                    self.conversation_history.append({
                        'user': transcript,
                        'ai': response
                    })
            
            history = self.get_conversation_history()
            
            return (transcript, response, history, status)
            
        except Exception as e:
            self.logger.error(f"Error polling updates: {e}")
            return ("", "", self.get_conversation_history(), f"‚ùå Erreur: {str(e)}")
    
    def get_conversation_history(self):
        """Get formatted conversation history."""
        if not self.conversation_history:
            return "Aucun historique de conversation"
        
        lines = ["üìú Historique de la conversation:\n"]
        for i, entry in enumerate(self.conversation_history, 1):
            user_text = entry.get('user', '')
            ai_text = entry.get('ai', '')
            lines.append(f"\n**Tour {i}:**")
            lines.append(f"üë§ Vous: {user_text}")
            lines.append(f"ü§ñ IA: {ai_text}")
        
        return "\n".join(lines)
    
    def clear_conversation_history(self):
        """Clear conversation history."""
        self.conversation_history = []
        return "‚úÖ Historique effac√©"
    
    def get_available_subjects(self):
        """Get list of available subjects."""
        try:
            orchestrator = self._get_orchestrator()
            subjects = orchestrator.get_available_subjects()
            return subjects if subjects else ['maths', 'physique', 'anglais']
        except Exception:
            return ['maths', 'physique', 'anglais']
    
    def build_interface(self) -> gr.Blocks:
        """
        Build Gradio interface.
        
        Returns:
            Gradio Blocks interface
        """
        with gr.Blocks(title=self.title, theme=self.theme) as interface:
            # Header
            gr.Markdown(f"# {self.title}")
            gr.Markdown(f"*{self.description}*")
            
            # Get available subjects
            available_subjects = self.get_available_subjects()
            
            # Settings row
            with gr.Row():
                subject_selector = gr.Dropdown(
                    choices=available_subjects,
                    value=available_subjects[0] if available_subjects else 'maths',
                    label="üìö Mati√®re",
                    info="S√©lectionnez la mati√®re"
                )
                auto_detect_checkbox = gr.Checkbox(
                    value=True,
                    label="üîç D√©tection automatique",
                    info="D√©tecte la mati√®re depuis la question"
                )
            
            # Main tabs
            with gr.Tabs():
                # Tab 1: Continuous Conversation (NEW!)
                with gr.Tab("üí¨ Conversation Continue"):
                    gr.Markdown("""
                    ### üé§ Mode Conversation Naturelle
                    
                    **Comment √ßa marche ?**
                    1. Cliquez sur "D√©marrer la conversation" üé§
                    2. Parlez naturellement (pas besoin de cliquer √† nouveau)
                    3. L'IA d√©tecte automatiquement quand vous avez fini de parler
                    4. L'IA r√©pond vocalement
                    5. Vous pouvez imm√©diatement continuer √† parler
                    6. Cliquez sur "Arr√™ter" quand vous avez termin√© üõë
                    
                    **‚ö° D√©tection automatique de fin de parole par VAD (Voice Activity Detection)**
                    """)
                    
                    # Conversation state
                    conversation_state = gr.State(value=False)
                    
                    with gr.Row():
                        toggle_conversation_btn = gr.Button(
                            "üé§ D√©marrer la conversation",
                            variant="primary",
                            size="lg"
                        )
                    
                    status_conversation = gr.Textbox(
                        label="üìä Statut",
                        value="Pr√™t √† d√©marrer",
                        interactive=False,
                        lines=2
                    )
                    
                    with gr.Row():
                        with gr.Column():
                            conversation_transcript = gr.Textbox(
                                label="üìù Derni√®re transcription",
                                lines=3,
                                interactive=False
                            )
                        
                        with gr.Column():
                            conversation_response = gr.Textbox(
                                label="üí° Derni√®re r√©ponse IA",
                                lines=6,
                                interactive=False
                            )
                    
                    conversation_history_display = gr.Textbox(
                        label="üìú Historique de la conversation",
                        lines=10,
                        interactive=False
                    )
                    
                    with gr.Row():
                        refresh_history_btn = gr.Button("üîÑ Actualiser l'historique")
                        clear_history_btn = gr.Button("üóëÔ∏è Effacer l'historique")
                    
                    # Connect conversation toggle
                    toggle_conversation_btn.click(
                        fn=self.toggle_conversation,
                        inputs=[conversation_state, subject_selector, auto_detect_checkbox],
                        outputs=[conversation_state, toggle_conversation_btn, 
                                toggle_conversation_btn, status_conversation,
                                conversation_transcript, conversation_response]
                    )
                    
                    # Polling for updates (every 2 seconds when active)
                    # Note: Gradio doesn't support true push updates, so we poll
                    def update_loop():
                        import time
                        while True:
                            time.sleep(2)
                            yield self.poll_conversation_updates(conversation_state.value)
                    
                    # Auto-refresh conversation display
                    conversation_state.change(
                        fn=self.poll_conversation_updates,
                        inputs=[conversation_state],
                        outputs=[conversation_transcript, conversation_response,
                                conversation_history_display, status_conversation],
                        every=2  # Poll every 2 seconds
                    )
                    
                    # Connect history buttons
                    refresh_history_btn.click(
                        fn=self.get_conversation_history,
                        outputs=conversation_history_display
                    )
                    
                    clear_history_btn.click(
                        fn=self.clear_conversation_history,
                        outputs=status_conversation
                    )
                
                # Tab 2: Audio Input (Manuel)
                with gr.Tab("üé§ Mode Vocal Manuel"):
                    gr.Markdown("### Posez votre question vocalement (enregistrement manuel)")
                    gr.Markdown("*Cliquez pour d√©marrer l'enregistrement, puis cliquez √† nouveau pour l'arr√™ter*")
                    
                    with gr.Row():
                        audio_input = gr.Audio(
                            sources=["microphone"],
                            type="numpy",
                            label="üé§ Enregistrement audio"
                        )
                    
                    process_audio_btn = gr.Button("üöÄ Traiter l'audio", variant="primary")
                    
                    with gr.Row():
                        transcript_output = gr.Textbox(
                            label="üìù Transcription",
                            lines=3,
                            interactive=False
                        )
                    
                    with gr.Row():
                        response_output_audio = gr.Textbox(
                            label="üí° R√©ponse du tuteur",
                            lines=8,
                            interactive=False
                        )
                    
                    with gr.Row():
                        sources_output_audio = gr.Textbox(
                            label="üìö Sources",
                            lines=3,
                            interactive=False
                        )
                    
                    with gr.Row():
                        audio_output = gr.Audio(
                            label="üîä R√©ponse vocale",
                            type="filepath"
                        )
                    
                    status_audio = gr.Textbox(
                        label="üìä Statut",
                        interactive=False
                    )
                    
                    # Connect audio processing
                    process_audio_btn.click(
                        fn=self.process_audio_input,
                        inputs=[audio_input, subject_selector, auto_detect_checkbox],
                        outputs=[transcript_output, response_output_audio, 
                                sources_output_audio, audio_output, status_audio]
                    )
                
                # Tab 3: Text Input
                with gr.Tab("üí¨ Mode Texte"):
                    gr.Markdown("### Posez votre question par √©crit")
                    
                    text_input = gr.Textbox(
                        label="‚úèÔ∏è Votre question",
                        placeholder="Ex: Comment r√©soudre une √©quation du second degr√© ?",
                        lines=3
                    )
                    
                    generate_audio_checkbox = gr.Checkbox(
                        value=True,
                        label="üîä G√©n√©rer l'audio",
                        info="Synth√©tiser la r√©ponse en audio"
                    )
                    
                    process_text_btn = gr.Button("üöÄ Envoyer", variant="primary")
                    
                    with gr.Row():
                        response_output_text = gr.Textbox(
                            label="üí° R√©ponse du tuteur",
                            lines=10,
                            interactive=False
                        )
                    
                    with gr.Row():
                        sources_output_text = gr.Textbox(
                            label="üìö Sources",
                            lines=3,
                            interactive=False
                        )
                    
                    with gr.Row():
                        audio_output_text = gr.Audio(
                            label="üîä R√©ponse vocale",
                            type="filepath"
                        )
                    
                    status_text = gr.Textbox(
                        label="üìä Statut",
                        interactive=False
                    )
                    
                    # Connect text processing
                    process_text_btn.click(
                        fn=self.process_text_input,
                        inputs=[text_input, subject_selector, auto_detect_checkbox, 
                               generate_audio_checkbox],
                        outputs=[response_output_text, sources_output_text, 
                                audio_output_text, status_text]
                    )
            
            # Footer
            gr.Markdown("---")
            gr.Markdown(
                "üí° **Conseil**: Le syst√®me fournit des indices progressifs pour vous aider "
                "√† comprendre par vous-m√™me. Ne vous attendez pas √† une r√©ponse compl√®te directe!"
            )
            gr.Markdown(
                "üîß **Note**: Tous les mod√®les fonctionnent localement (offline). "
                "La premi√®re utilisation peut prendre quelques secondes pour charger les mod√®les."
            )
        
        return interface
    
    def launch(
        self,
        share: bool = False,
        server_port: int = None,
        server_name: str = None
    ):
        """
        Launch Gradio interface.
        
        Args:
            share: Create public link
            server_port: Server port
            server_name: Server name/IP
        """
        port = server_port or self.config.get('ui.server_port', 7860)
        share = share or self.config.get('ui.share', False)
        
        interface = self.build_interface()
        
        self.logger.info(f"Launching UI on port {port} (share={share})")
        
        interface.launch(
            share=share,
            server_port=port,
            server_name=server_name,
            show_error=True
        )


def launch_ui(config_path: str = "config.yaml", share: bool = False):
    """
    Convenience function to launch UI.
    
    Args:
        config_path: Path to config file
        share: Create public link
    """
    ui = VocalTutorUI(config_path)
    ui.launch(share=share)


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Launch Vocal Tutor UI")
    parser.add_argument('--config', type=str, default='config.yaml', help="Config file")
    parser.add_argument('--share', action='store_true', help="Create public link")
    parser.add_argument('--port', type=int, default=7860, help="Server port")
    
    args = parser.parse_args()
    
    ui = VocalTutorUI(args.config)
    ui.launch(share=args.share, server_port=args.port)
