{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa181988",
   "metadata": {},
   "source": [
    "# üéì Agent Vocal IA - Setup Colab\n",
    "\n",
    "Notebook d'installation et de v√©rification pour l'Agent Vocal IA √©ducatif 100% local.\n",
    "\n",
    "**Fonctionnalit√©s :**\n",
    "- üé§ ASR (Faster-Whisper + Silero VAD)\n",
    "- üîç RAG (FAISS + SentenceTransformers)\n",
    "- üß† LLM local (llama-cpp-python)\n",
    "- üîä TTS (gTTS/pyttsx3 - Python 3.12 compatible)\n",
    "- üí° Syst√®me de hints progressifs\n",
    "\n",
    "**Pr√©requis :** GPU T4 ou A100 recommand√©\n",
    "\n",
    "---\n",
    "\n",
    "‚ö†Ô∏è **IMPORTANT** : Activez le GPU avant de commencer !\n",
    "- Menu **Runtime** ‚Üí **Change runtime type** ‚Üí **T4 GPU** ‚Üí **Save**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b384b0f9",
   "metadata": {},
   "source": [
    "## üìã √âtape 1 : V√©rification de l'environnement\n",
    "\n",
    "V√©rifions d'abord que nous avons bien acc√®s √† un GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134fba74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# V√©rification GPU et CUDA\n",
    "import subprocess\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üñ•Ô∏è  INFORMATIONS SYST√àME\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Plateforme: {platform.platform()}\")\n",
    "print()\n",
    "\n",
    "# V√©rifier NVIDIA GPU\n",
    "print(\"=\" * 60)\n",
    "print(\"üéÆ  V√âRIFICATION GPU\")\n",
    "print(\"=\" * 60)\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, check=True)\n",
    "    print(result.stdout)\n",
    "    print(\"‚úÖ GPU NVIDIA d√©tect√©!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Aucun GPU d√©tect√©. L'ex√©cution sera tr√®s lente sur CPU.\")\n",
    "    print(f\"   Activez le GPU: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\")\n",
    "\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884ddf37",
   "metadata": {},
   "source": [
    "## üì• √âtape 2 : Clonage du projet\n",
    "\n",
    "T√©l√©chargeons le projet depuis GitHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e03e0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Retourner √† /content si dans un sous-dossier\n",
    "if '/content/' in os.getcwd() and os.getcwd() != '/content':\n",
    "    %cd /content\n",
    "\n",
    "# Nettoyer ancien dossier\n",
    "if os.path.exists('agent_vocal_IA'):\n",
    "    print(\"üóëÔ∏è  Suppression ancienne installation...\")\n",
    "    !rm -rf agent_vocal_IA\n",
    "\n",
    "# Cloner\n",
    "print(\"üì• Clonage...\")\n",
    "!git clone -q https://github.com/Romainmlt123/agent_vocal_IA.git\n",
    "%cd agent_vocal_IA\n",
    "\n",
    "print(f\"‚úÖ Projet clon√©: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cde6d4a",
   "metadata": {},
   "source": [
    "## üì¶ √âtape 3 : Installation des d√©pendances\n",
    "\n",
    "Installation de toutes les biblioth√®ques requises. **Cela peut prendre 5-10 minutes.**\n",
    "\n",
    "### ‚ö†Ô∏è Compatibilit√© Python 3.12+\n",
    "\n",
    "Google Colab utilise Python 3.12, ce qui pose des probl√®mes :\n",
    "\n",
    "- **‚ùå Piper-TTS** : Non compatible Python 3.12+\n",
    "- **‚ùå Coqui TTS** : Non compatible Python 3.12+\n",
    "- **‚úÖ gTTS** : Compatible (n√©cessite internet)\n",
    "- **‚úÖ pyttsx3** : Compatible (TTS syst√®me)\n",
    "\n",
    "### üîß Ce que fait la cellule suivante\n",
    "\n",
    "1. Installe **PortAudio** (r√©sout erreur sounddevice)\n",
    "2. G√®re les conflits **NumPy** (force <2.0)\n",
    "3. FAISS-GPU ‚Üí fallback FAISS-CPU\n",
    "4. llama-cpp-python avec CUDA\n",
    "5. gTTS + pyttsx3 pour TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b984d57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "print(\"üîÑ Installation...\\n\")\n",
    "\n",
    "# 1. PortAudio\n",
    "print(\"1/8 PortAudio...\")\n",
    "!apt-get update -qq > /dev/null 2>&1\n",
    "!apt-get install -qq -y portaudio19-dev > /dev/null 2>&1\n",
    "\n",
    "# 2. D√©sinstaller packages incompatibles NumPy 2.0\n",
    "print(\"2/8 Nettoyage environnement...\")\n",
    "!pip uninstall -y -q opencv-python opencv-python-headless opencv-contrib-python jax jaxlib pytensor thinc 2>/dev/null\n",
    "\n",
    "# 3. NumPy <2.0 (CRITIQUE pour sentence-transformers)\n",
    "print(\"3/8 NumPy <2.0...\")\n",
    "!pip install --force-reinstall -q 'numpy>=1.24,<2.0'\n",
    "\n",
    "# 4. R√©installer opencv compatible\n",
    "print(\"4/8 OpenCV compatible...\")\n",
    "!pip install -q 'opencv-python-headless>=4.5,<4.10'\n",
    "\n",
    "# 5. Packages base\n",
    "print(\"5/8 Packages base...\")\n",
    "!pip install -q torch torchaudio faster-whisper==1.0.3 sentence-transformers==2.7.0 pypdf==4.2.0 langchain==0.2.11 langchain-community==0.2.10 gradio>=4.44.0 pyyaml>=6.0.2 soundfile sounddevice\n",
    "\n",
    "# 6. FAISS\n",
    "print(\"6/8 FAISS...\")\n",
    "if subprocess.run(['pip','install','-q','faiss-gpu'], capture_output=True).returncode != 0:\n",
    "    !pip install -q faiss-cpu==1.8.0\n",
    "\n",
    "# 7. Silero VAD\n",
    "print(\"7/8 Silero VAD...\")\n",
    "!pip install -q silero-vad\n",
    "\n",
    "# 8. llama-cpp-python\n",
    "print(\"8/8 llama-cpp-python...\")\n",
    "if subprocess.run(['pip','install','-q','llama-cpp-python','--extra-index-url','https://abetlen.github.io/llama-cpp-python/whl/cu121'], capture_output=True).returncode != 0:\n",
    "    !pip install -q llama-cpp-python\n",
    "\n",
    "# 9. TTS\n",
    "print(\"9/9 TTS...\")\n",
    "!pip install -q gTTS pyttsx3\n",
    "\n",
    "print(\"\\n‚úÖ Installation termin√©e!\")\n",
    "print(\"üìù TTS: gTTS install√© (Piper incompatible Python 3.12+)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473f8c7e",
   "metadata": {},
   "source": [
    "## ‚úÖ √âtape 4 : V√©rification des imports\n",
    "\n",
    "Testons que tous les modules principaux peuvent √™tre import√©s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ea0e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ö†Ô∏è  IMPORTANT: Red√©marrer le kernel apr√®s installation NumPy\n",
    "print(\"‚ö†Ô∏è  RED√âMARRAGE KERNEL...\")\n",
    "print(\"   N√©cessaire apr√®s r√©installation NumPy\\n\")\n",
    "\n",
    "import os\n",
    "os.kill(os.getpid(), 9)  # Force restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test imports apr√®s restart\n",
    "import sys\n",
    "\n",
    "def test(module, name=None):\n",
    "    name = name or module\n",
    "    try:\n",
    "        __import__(module.split('.')[0])\n",
    "        print(f\"‚úÖ {name}\")\n",
    "        return True\n",
    "    except:\n",
    "        print(f\"‚ùå {name}\")\n",
    "        return False\n",
    "\n",
    "print(\"üìö V√©rification...\\n\")\n",
    "r = [\n",
    "    test('torch'),\n",
    "    test('faster_whisper'),\n",
    "    test('sentence_transformers'),\n",
    "    test('faiss'),\n",
    "    test('langchain'),\n",
    "    test('llama_cpp'),\n",
    "    test('gradio'),\n",
    "    test('numpy'),\n",
    "    test('sounddevice'),\n",
    "    test('gtts')\n",
    "]\n",
    "\n",
    "print(f\"\\nüìä {sum(r)}/{len(r)} modules OK\")\n",
    "if sum(r) == len(r):\n",
    "    print(\"üéâ Pr√™t!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Certains modules manquent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb033078",
   "metadata": {},
   "source": [
    "## üì• √âtape 5 : T√©l√©chargement des mod√®les\n",
    "\n",
    "T√©l√©chargement des mod√®les LLM. **Dur√©e : 10-15 minutes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f471c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "def download_file(url, destination, description=\"Fichier\"):\n",
    "    print(f\"üì• {description}...\")\n",
    "    print(f\"   ‚Üí {destination}\")\n",
    "    \n",
    "    os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
    "    \n",
    "    if os.path.exists(destination):\n",
    "        print(f\"   ‚úÖ D√©j√† pr√©sent\")\n",
    "        return True\n",
    "    \n",
    "    try:\n",
    "        def progress(block, block_size, total):\n",
    "            percent = min(100, block * block_size * 100 / total) if total > 0 else 0\n",
    "            bar = '‚ñà' * int(percent / 2.5) + '‚ñë' * (40 - int(percent / 2.5))\n",
    "            print(f'\\r   [{bar}] {percent:.1f}%', end='', flush=True)\n",
    "        \n",
    "        urllib.request.urlretrieve(url, destination, progress)\n",
    "        print(f\"\\n   ‚úÖ T√©l√©charg√©!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"\\n   ‚ùå Erreur: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üì¶ T√âL√âCHARGEMENT DES MOD√àLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "Path(\"models/llm\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\nü¶ô Mod√®le LLM (Phi-3 Mini - 2.4 GB)\")\n",
    "llm_url = \"https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf\"\n",
    "llm_dest = \"models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf\"\n",
    "download_file(llm_url, llm_dest, \"Phi-3 Mini 4K\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ T√©l√©chargement termin√©!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cd1176",
   "metadata": {},
   "source": [
    "## üß™ √âtape 6 : Construction des indices RAG\n",
    "\n",
    "Construisons les indices pour les 3 mati√®res."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ed7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 60)\n",
    "print(\"üîç CONSTRUCTION DES INDICES RAG\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "print(\"\\nüìê Math√©matiques...\")\n",
    "!python -m src.rag_build --subject maths\n",
    "\n",
    "print(\"\\n‚ö° Physique...\")\n",
    "!python -m src.rag_build --subject physique\n",
    "\n",
    "print(\"\\nüá¨üáß Anglais...\")\n",
    "!python -m src.rag_build --subject anglais\n",
    "\n",
    "print(\"\\n=\" * 60)\n",
    "print(\"‚úÖ Indices RAG construits!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d53e0c94",
   "metadata": {},
   "source": [
    "## üöÄ √âtape 7 : Lancement de l'interface\n",
    "\n",
    "Lan√ßons l'interface Gradio avec lien public."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104f5402",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Lancement de l'interface Gradio...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "from ui.app import launch_ui\n",
    "\n",
    "# Lancer avec lien public\n",
    "launch_ui(share=True)\n",
    "\n",
    "print(\"\\nüìù Cliquez sur le lien ci-dessus pour acc√©der √† l'interface\")\n",
    "print(\"‚ö†Ô∏è  Le micro ne fonctionne pas dans l'iframe Colab, utilisez le lien public!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f70796",
   "metadata": {},
   "source": [
    "## üéâ Installation termin√©e !\n",
    "\n",
    "Votre Agent Vocal IA est pr√™t. Cliquez sur le lien Gradio ci-dessus.\n",
    "\n",
    "### ‚ö†Ô∏è Note importante sur TTS\n",
    "\n",
    "Python 3.12+ n'est pas compatible avec Piper-TTS. Vous avez 2 options :\n",
    "\n",
    "1. **Utiliser le mode Texte** (pas de synth√®se vocale)\n",
    "2. **Adapter le code** pour utiliser gTTS (n√©cessite modification de `src/tts.py`)\n",
    "\n",
    "Pour les tests, le mode texte fonctionne parfaitement !"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5cf5c91",
   "metadata": {
    "id": "f5cf5c91"
   },
   "source": [
    "# üéì Agent Vocal IA - Setup Colab\n",
    "\n",
    "Notebook d'installation et de v√©rification pour l'Agent Vocal IA √©ducatif 100% local.\n",
    "\n",
    "**Fonctionnalit√©s :**\n",
    "- üé§ ASR (Faster-Whisper + Silero VAD)\n",
    "- üîç RAG (FAISS + SentenceTransformers)\n",
    "- üß† LLM local (llama-cpp-python)\n",
    "- üîä TTS (Piper-TTS)\n",
    "- üí° Syst√®me de hints progressifs\n",
    "\n",
    "**Pr√©requis :** GPU T4 ou A100 recommand√©"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91363323",
   "metadata": {
    "id": "91363323"
   },
   "source": [
    "## üìã √âtape 1 : V√©rification de l'environnement\n",
    "\n",
    "V√©rifions d'abord que nous avons bien acc√®s √† un GPU et les informations syst√®me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5555ef2c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5555ef2c",
    "outputId": "00ee38fa-47cc-4023-b4ba-bf85446ca25a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üñ•Ô∏è  INFORMATIONS SYST√àME\n",
      "============================================================\n",
      "Python version: 3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "Plateforme: Linux-6.6.105+-x86_64-with-glibc2.35\n",
      "Architecture: x86_64\n",
      "\n",
      "============================================================\n",
      "üéÆ  V√âRIFICATION GPU\n",
      "============================================================\n",
      "Wed Oct 29 20:07:40 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
      "| N/A   46C    P8              9W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "\n",
      "\n",
      "============================================================\n",
      "üì¶  V√âRIFICATION PYTORCH\n",
      "============================================================\n",
      "PyTorch version: 2.8.0+cu126\n",
      "CUDA disponible: True\n",
      "CUDA version: 12.6\n",
      "Nombre de GPUs: 1\n",
      "  GPU 0: Tesla T4\n",
      "    M√©moire totale: 15.83 GB\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# V√©rification GPU et CUDA\n",
    "import subprocess\n",
    "import sys\n",
    "import platform\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üñ•Ô∏è  INFORMATIONS SYST√àME\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Plateforme: {platform.platform()}\")\n",
    "print(f\"Architecture: {platform.machine()}\")\n",
    "print()\n",
    "\n",
    "# V√©rifier NVIDIA GPU\n",
    "print(\"=\" * 60)\n",
    "print(\"üéÆ  V√âRIFICATION GPU\")\n",
    "print(\"=\" * 60)\n",
    "try:\n",
    "    result = subprocess.run(['nvidia-smi'], capture_output=True, text=True, check=True)\n",
    "    print(result.stdout)\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Aucun GPU NVIDIA d√©tect√© ou nvidia-smi non disponible: {e}\")\n",
    "    print(\"Note: L'ex√©cution sera possible sur CPU mais beaucoup plus lente.\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 60)\n",
    "print(\"üì¶  V√âRIFICATION PYTORCH\")\n",
    "print(\"=\" * 60)\n",
    "try:\n",
    "    import torch\n",
    "    print(f\"PyTorch version: {torch.__version__}\")\n",
    "    print(f\"CUDA disponible: {torch.cuda.is_available()}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA version: {torch.version.cuda}\")\n",
    "        print(f\"Nombre de GPUs: {torch.cuda.device_count()}\")\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            print(f\"  GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "            print(f\"    M√©moire totale: {torch.cuda.get_device_properties(i).total_memory / 1e9:.2f} GB\")\n",
    "except ImportError:\n",
    "    print(\"PyTorch n'est pas encore install√©. Il sera install√© √† l'√©tape suivante.\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1474ff89",
   "metadata": {
    "id": "1474ff89"
   },
   "source": [
    "## üì• √âtape 2 : Clonage du d√©p√¥t (si n√©cessaire)\n",
    "\n",
    "Si vous n'avez pas encore clon√© le d√©p√¥t, d√©commentez et ex√©cutez la cellule suivante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da884b80",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da884b80",
    "outputId": "3ea1c70a-0b69-43da-bce8-7e601079f355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'agent_vocal_IA'...\n",
      "remote: Enumerating objects: 117, done.\u001b[K\n",
      "remote: Counting objects: 100% (117/117), done.\u001b[K\n",
      "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
      "remote: Total 117 (delta 18), reused 106 (delta 11), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (117/117), 240.99 KiB | 1.85 MiB/s, done.\n",
      "Resolving deltas: 100% (18/18), done.\n",
      "/content/agent_vocal_IA\n",
      "üìÅ Dossier actuel: /content/agent_vocal_IA\n",
      "\n",
      "üìÇ Structure du projet:\n",
      "./\n",
      "  CHANGELOG.md\n",
      "  Cahier des charges - Intelligence Lab - Romain Mallet (1).pdf\n",
      "  README.md\n",
      "  demo_cli.py\n",
      "  LICENSE\n",
      "  requirements.txt\n",
      "  setup_colab.ipynb\n",
      "  test_conversation.py\n",
      "  config.yaml\n",
      "  src/\n",
      "    orchestrator.py\n",
      "    rag_build.py\n",
      "    llm.py\n",
      "    rag.py\n",
      "    utils.py\n",
      "    __init__.py\n",
      "    tts.py\n",
      "    conversation_manager.py\n",
      "    asr.py\n",
      "  ui/\n",
      "    __init__.py\n",
      "    app.py\n",
      "  data/\n",
      "    maths/\n",
      "      cours_maths.md\n",
      "    physique/\n",
      "      cours_physique.md\n",
      "    anglais/\n",
      "      english_grammar.md\n",
      "  tests/\n",
      "    test_utils.py\n",
      "    __init__.py\n",
      "    test_integration.py\n",
      "    test_rag.py\n",
      "  .git/\n",
      "    description\n",
      "    packed-refs\n",
      "    config\n",
      "    index\n",
      "    HEAD\n",
      "    hooks/\n",
      "      pre-applypatch.sample\n",
      "      pre-commit.sample\n",
      "      pre-receive.sample\n",
      "      pre-rebase.sample\n",
      "      fsmonitor-watchman.sample\n",
      "      push-to-checkout.sample\n",
      "      pre-merge-commit.sample\n",
      "      pre-push.sample\n",
      "      prepare-commit-msg.sample\n",
      "      post-update.sample\n",
      "      update.sample\n",
      "      applypatch-msg.sample\n",
      "      commit-msg.sample\n",
      "    objects/\n",
      "    info/\n",
      "      exclude\n",
      "    branches/\n",
      "    logs/\n",
      "      HEAD\n",
      "    refs/\n"
     ]
    }
   ],
   "source": [
    "# D√©commentez les lignes suivantes si vous devez cloner le d√©p√¥t\n",
    "!git clone https://github.com/Romainmlt123/agent_vocal_IA.git\n",
    "%cd agent_vocal_IA\n",
    "\n",
    "# Si vous √™tes d√©j√† dans le dossier, v√©rifiez la structure\n",
    "import os\n",
    "print(\"üìÅ Dossier actuel:\", os.getcwd())\n",
    "print(\"\\nüìÇ Structure du projet:\")\n",
    "for root, dirs, files in os.walk('.', topdown=True):\n",
    "    # Limiter la profondeur pour la lisibilit√©\n",
    "    level = root.replace('.', '').count(os.sep)\n",
    "    if level < 3:\n",
    "        indent = ' ' * 2 * level\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 2 * (level + 1)\n",
    "        for file in files:\n",
    "            if not file.startswith('.'):\n",
    "                print(f'{subindent}{file}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5b9634",
   "metadata": {
    "id": "3c5b9634"
   },
   "source": [
    "## üì¶ √âtape 3 : Installation des d√©pendances\n",
    "\n",
    "Installation de toutes les biblioth√®ques requises. **Cela peut prendre 5-10 minutes.**\n",
    "\n",
    "### ‚ö†Ô∏è Compatibilit√© Python 3.12+\n",
    "\n",
    "Google Colab utilise Python 3.12, ce qui pose des probl√®mes avec certaines biblioth√®ques :\n",
    "\n",
    "- **‚ùå Piper-TTS** : Non compatible Python 3.12+ (seulement 3.9-3.11)\n",
    "- **‚ùå Coqui TTS** : Non compatible Python 3.12+ (seulement 3.9-3.11)\n",
    "- **‚úÖ gTTS** : Compatible, mais n√©cessite internet\n",
    "- **‚úÖ pyttsx3** : Compatible, TTS syst√®me\n",
    "\n",
    "### üîß Solutions Automatiques\n",
    "\n",
    "La cellule suivante :\n",
    "1. Installe **PortAudio** (requis pour sounddevice)\n",
    "2. G√®re les conflits **NumPy** (force <2.0 pour compatibilit√©)\n",
    "3. Essaie **FAISS-GPU** ‚Üí fallback **FAISS-CPU**\n",
    "4. Installe **llama-cpp-python** avec wheels pr√©compil√©s CUDA\n",
    "5. Pour TTS :\n",
    "   - Python 3.12+ ‚Üí installe **gTTS + pyttsx3**\n",
    "   - Python 3.10/3.11 ‚Üí essaie **Piper-TTS**, sinon gTTS\n",
    "\n",
    "**Note** : Si vous avez besoin de Piper-TTS, vous devrez utiliser un runtime Python 3.10 ou 3.11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a0836c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86a0836c",
    "outputId": "6b0bf2df-d132-4a07-8e14-0e773e936512"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Installation des packages...\n",
      "============================================================\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m49.3/49.3 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m83.5/83.5 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: Ignored the following versions that require a different python version: 0.5.12 Requires-Python >=3.7,<3.12; 0.5.13 Requires-Python >=3.7,<3.12; 1.21.2 Requires-Python >=3.7,<3.11; 1.21.3 Requires-Python >=3.7,<3.11; 1.21.4 Requires-Python >=3.7,<3.11; 1.21.5 Requires-Python >=3.7,<3.11; 1.21.6 Requires-Python >=3.7,<3.11\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement piper-phonemize~=1.1.0 (from piper-tts) (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for piper-phonemize~=1.1.0\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "üìä Installation de FAISS-GPU pour meilleures performances...\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement faiss-gpu (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for faiss-gpu\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "ü¶ô Installation de llama-cpp-python avec support CUDA...\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.7/50.7 MB\u001b[0m \u001b[31m315.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
      "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
      "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m319.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m301.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m414.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m261.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m315.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m√ó\u001b[0m \u001b[32mBuilding wheel for llama-cpp-python \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m‚îÇ\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m‚ï∞‚îÄ>\u001b[0m See above for output.\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25herror\n",
      "\u001b[31m  ERROR: Failed building wheel for llama-cpp-python\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: ERROR: Failed to build installable wheels for some pyproject.toml based projects (llama-cpp-python)\u001b[0m\u001b[31m\n",
      "\u001b[0m\n",
      "‚úÖ Installation termin√©e!\n"
     ]
    }
   ],
   "source": [
    "# Installation des d√©pendances - Version optimis√©e pour Colab\n",
    "print(\"üîÑ Installation des packages...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# V√©rifier la version de Python\n",
    "import sys\n",
    "print(f\"üìå Python version: {sys.version}\")\n",
    "\n",
    "# √âtape 1 : Installer les d√©pendances de base sans les packages probl√©matiques\n",
    "print(\"\\nüì¶ √âtape 1/5 : Installation des packages de base...\")\n",
    "!pip install -q torch>=2.0.0 torchaudio>=2.0.0\n",
    "!pip install -q faster-whisper==1.0.3\n",
    "!pip install -q sentence-transformers==2.7.0\n",
    "!pip install -q pypdf==4.2.0\n",
    "!pip install -q langchain==0.2.11 langchain-community==0.2.10\n",
    "!pip install -q gradio==4.36.1\n",
    "!pip install -q pyyaml==6.0.1\n",
    "!pip install -q numpy scipy soundfile sounddevice\n",
    "\n",
    "# √âtape 2 : Installer FAISS (essayer GPU d'abord, puis CPU en fallback)\n",
    "print(\"\\nüìä √âtape 2/5 : Installation de FAISS...\")\n",
    "import subprocess\n",
    "result = subprocess.run(['pip', 'install', '-q', 'faiss-gpu'], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úÖ FAISS-GPU install√© avec succ√®s!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  FAISS-GPU non disponible, installation de FAISS-CPU...\")\n",
    "    !pip install -q faiss-cpu==1.8.0\n",
    "\n",
    "# √âtape 3 : Installer Silero VAD\n",
    "print(\"\\nüéôÔ∏è  √âtape 3/5 : Installation de Silero VAD...\")\n",
    "!pip install -q silero-vad\n",
    "\n",
    "# √âtape 4 : Installer llama-cpp-python (version pr√©compil√©e)\n",
    "print(\"\\nü¶ô √âtape 4/5 : Installation de llama-cpp-python...\")\n",
    "print(\"   Tentative avec version CUDA pr√©compil√©e...\")\n",
    "result = subprocess.run(['pip', 'install', '-q', 'llama-cpp-python', '--extra-index-url', 'https://abetlen.github.io/llama-cpp-python/whl/cu121'], capture_output=True, text=True)\n",
    "if result.returncode == 0:\n",
    "    print(\"‚úÖ llama-cpp-python avec CUDA install√©!\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Version CUDA √©chou√©e, installation version standard...\")\n",
    "    !pip install -q llama-cpp-python==0.2.85\n",
    "\n",
    "# √âtape 5 : TTS - Utiliser une alternative compatible\n",
    "print(\"\\nüîä √âtape 5/5 : Configuration TTS...\")\n",
    "print(\"‚ö†Ô∏è  Note: piper-tts n'est pas compatible avec Python 3.12+\")\n",
    "print(\"   Installation de Coqui TTS comme alternative compatible...\")\n",
    "!pip install -q TTS>=0.22.0\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Installation termin√©e!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüìù Notes importantes:\")\n",
    "print(\"   ‚Ä¢ Si llama-cpp-python a √©chou√©, le LLM utilisera le CPU\")\n",
    "print(\"   ‚Ä¢ Pour TTS, nous utilisons Coqui TTS au lieu de Piper\")\n",
    "print(\"   ‚Ä¢ V√©rifiez les imports dans la cellule suivante\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ac0ed4",
   "metadata": {
    "id": "08ac0ed4"
   },
   "source": [
    "## ‚úÖ √âtape 4 : V√©rification des imports\n",
    "\n",
    "Testons que tous les modules principaux peuvent √™tre import√©s correctement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce6254",
   "metadata": {
    "id": "13ce6254"
   },
   "outputs": [],
   "source": [
    "# Test des imports critiques\n",
    "import sys\n",
    "\n",
    "def test_import(module_name, display_name=None, alternative_names=None):\n",
    "    \"\"\"Test l'import d'un module et affiche le r√©sultat.\"\"\"\n",
    "    if display_name is None:\n",
    "        display_name = module_name\n",
    "    \n",
    "    # Essayer le module principal\n",
    "    try:\n",
    "        module = __import__(module_name.split('.')[0])\n",
    "        version = getattr(module, '__version__', 'version inconnue')\n",
    "        print(f\"‚úÖ {display_name:30} - {version}\")\n",
    "        return True\n",
    "    except ImportError as e:\n",
    "        # Essayer les alternatives si fournies\n",
    "        if alternative_names:\n",
    "            for alt_name in alternative_names:\n",
    "                try:\n",
    "                    module = __import__(alt_name.split('.')[0])\n",
    "                    version = getattr(module, '__version__', 'version inconnue')\n",
    "                    print(f\"‚úÖ {display_name:30} - {version} (via {alt_name})\")\n",
    "                    return True\n",
    "                except ImportError:\n",
    "                    continue\n",
    "        \n",
    "        print(f\"‚ùå {display_name:30} - NON DISPONIBLE\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è  {display_name:30} - ERREUR: {str(e)[:50]}\")\n",
    "        return False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üìö V√âRIFICATION DES BIBLIOTH√àQUES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "modules_to_test = [\n",
    "    ('torch', 'PyTorch', None),\n",
    "    ('torchaudio', 'TorchAudio', None),\n",
    "    ('faster_whisper', 'Faster-Whisper (ASR)', None),\n",
    "    ('silero_vad', 'Silero VAD', None),\n",
    "    ('sentence_transformers', 'SentenceTransformers', None),\n",
    "    ('faiss', 'FAISS', None),\n",
    "    ('pypdf', 'PyPDF', None),\n",
    "    ('langchain', 'LangChain', None),\n",
    "    ('llama_cpp', 'llama-cpp-python', None),\n",
    "    ('gradio', 'Gradio', None),\n",
    "    ('yaml', 'PyYAML', None),\n",
    "    ('numpy', 'NumPy', None),\n",
    "    ('soundfile', 'SoundFile', None),\n",
    "    ('sounddevice', 'SoundDevice', None),\n",
    "]\n",
    "\n",
    "# Test TTS selon ce qui est install√©\n",
    "python_version = sys.version_info\n",
    "if python_version.minor >= 12:\n",
    "    modules_to_test.append(('gtts', 'gTTS (TTS fallback)', ['pyttsx3']))\n",
    "else:\n",
    "    modules_to_test.append(('piper', 'Piper-TTS', ['gtts', 'TTS']))\n",
    "\n",
    "results = []\n",
    "for module_info in modules_to_test:\n",
    "    if len(module_info) == 3:\n",
    "        module, name, alts = module_info\n",
    "        results.append(test_import(module, name, alts))\n",
    "    else:\n",
    "        module, name = module_info\n",
    "        results.append(test_import(module, name))\n",
    "\n",
    "print(\"=\" * 60)\n",
    "success_count = sum(results)\n",
    "total_count = len(results)\n",
    "print(f\"\\nüìä R√©sultat: {success_count}/{total_count} modules import√©s avec succ√®s\")\n",
    "\n",
    "if success_count == total_count:\n",
    "    print(\"üéâ Tous les modules sont pr√™ts!\")\n",
    "elif success_count >= total_count - 2:\n",
    "    print(\"‚úÖ La plupart des modules sont pr√™ts!\")\n",
    "    print(\"üí° Les modules manquants ne sont pas critiques pour le fonctionnement de base.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Plusieurs modules ont √©chou√©. V√©rifiez les erreurs ci-dessus.\")\n",
    "    print(\"üí° R√©ex√©cutez la cellule d'installation si n√©cessaire.\")\n",
    "\n",
    "# Test sp√©cial pour sounddevice (PortAudio)\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéµ TEST SP√âCIAL: SoundDevice/PortAudio\")\n",
    "print(\"=\" * 60)\n",
    "try:\n",
    "    import sounddevice as sd\n",
    "    devices = sd.query_devices()\n",
    "    print(f\"‚úÖ SoundDevice op√©rationnel - {len(devices)} p√©riph√©riques audio d√©tect√©s\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  SoundDevice erreur: {str(e)[:100]}\")\n",
    "    print(\"   Note: Normal sur Colab (pas de p√©riph√©riques audio virtuels)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a4a14b",
   "metadata": {
    "id": "a8a4a14b"
   },
   "source": [
    "## üì• √âtape 5 : T√©l√©chargement des mod√®les\n",
    "\n",
    "T√©l√©chargement des mod√®les LLM et voix TTS. **Attention: peut prendre 10-15 minutes selon la connexion.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd1be916",
   "metadata": {
    "id": "dd1be916"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "def download_file(url, destination, description=\"Fichier\"):\n",
    "    \"\"\"T√©l√©charge un fichier avec barre de progression.\"\"\"\n",
    "    print(f\"üì• T√©l√©chargement de {description}...\")\n",
    "    print(f\"   URL: {url}\")\n",
    "    print(f\"   Destination: {destination}\")\n",
    "\n",
    "    os.makedirs(os.path.dirname(destination), exist_ok=True)\n",
    "\n",
    "    if os.path.exists(destination):\n",
    "        print(f\"   ‚úÖ Fichier d√©j√† pr√©sent, t√©l√©chargement ignor√©.\")\n",
    "        return True\n",
    "\n",
    "    try:\n",
    "        def progress_hook(block_num, block_size, total_size):\n",
    "            downloaded = block_num * block_size\n",
    "            percent = min(100, downloaded * 100 / total_size) if total_size > 0 else 0\n",
    "            bar_length = 40\n",
    "            filled = int(bar_length * percent / 100)\n",
    "            bar = '‚ñà' * filled + '‚ñë' * (bar_length - filled)\n",
    "            print(f'\\r   [{bar}] {percent:.1f}%', end='', flush=True)\n",
    "\n",
    "        urllib.request.urlretrieve(url, destination, progress_hook)\n",
    "        print(f\"\\n   ‚úÖ T√©l√©chargement r√©ussi!\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"\\n   ‚ùå Erreur: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"üì¶ T√âL√âCHARGEMENT DES MOD√àLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Cr√©er les dossiers n√©cessaires\n",
    "Path(\"models/llm\").mkdir(parents=True, exist_ok=True)\n",
    "Path(\"models/voices\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\nü¶ô Mod√®le LLM (Phi-3 Mini 4K Instruct - Q4_K_M)\")\n",
    "print(\"-\" * 60)\n",
    "llm_url = \"https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf\"\n",
    "llm_dest = \"models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf\"\n",
    "download_file(llm_url, llm_dest, \"Phi-3 Mini 4K (2.4 GB)\")\n",
    "\n",
    "print(\"\\n\\nüîä Mod√®le TTS (Piper - Voix fran√ßaise Siwis)\")\n",
    "print(\"-\" * 60)\n",
    "tts_model_url = \"https://huggingface.co/rhasspy/piper-voices/resolve/main/fr/fr_FR/siwis/medium/fr_FR-siwis-medium.onnx\"\n",
    "tts_config_url = \"https://huggingface.co/rhasspy/piper-voices/resolve/main/fr/fr_FR/siwis/medium/fr_FR-siwis-medium.onnx.json\"\n",
    "tts_model_dest = \"models/voices/fr_FR-siwis-medium.onnx\"\n",
    "tts_config_dest = \"models/voices/fr_FR-siwis-medium.onnx.json\"\n",
    "\n",
    "download_file(tts_model_url, tts_model_dest, \"Voix TTS fran√ßaise (60 MB)\")\n",
    "download_file(tts_config_url, tts_config_dest, \"Config TTS\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üéâ T√©l√©chargement des mod√®les termin√©!\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4bced3",
   "metadata": {},
   "source": [
    "### ‚ö†Ô∏è Note CRITIQUE sur TTS et Python 3.12+\n",
    "\n",
    "**PROBL√àME** : Ni Piper-TTS ni Coqui TTS ne fonctionnent avec Python 3.12+.\n",
    "\n",
    "**Ce que nous avons install√©** : gTTS + pyttsx3 (alternatives)\n",
    "\n",
    "**3 SOLUTIONS POSSIBLES** :\n",
    "\n",
    "#### Solution 1 : Utiliser gTTS (Recommand√© pour tests)\n",
    "```python\n",
    "from gtts import gTTS\n",
    "tts = gTTS(\"Bonjour\", lang='fr')\n",
    "tts.save(\"output.mp3\")\n",
    "```\n",
    "**‚úÖ Avantage** : Simple, fonctionne imm√©diatement  \n",
    "**‚ùå Inconv√©nient** : N√©cessite internet, qualit√© moyenne\n",
    "\n",
    "#### Solution 2 : Modifier le code du projet\n",
    "Vous devez adapter `src/tts.py` pour utiliser gTTS au lieu de Piper.\n",
    "\n",
    "#### Solution 3 : Downgrade Python (Solution propre)\n",
    "```python\n",
    "# ‚ö†Ô∏è  ATTENTION: Cela va red√©marrer le runtime !\n",
    "# D√©commentez les lignes suivantes pour downgrade vers Python 3.10\n",
    "# !sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.10 1\n",
    "# !sudo update-alternatives --config python3\n",
    "# import os\n",
    "# os.kill(os.getpid(), 9)  # Force restart\n",
    "```\n",
    "\n",
    "**RECOMMANDATION** : Pour l'instant, continuez avec gTTS. Les mod√®les Piper t√©l√©charg√©s ci-dessus resteront disponibles si vous downgrade Python plus tard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3ca0e2",
   "metadata": {
    "id": "8c3ca0e2"
   },
   "source": [
    "## üß™ √âtape 6 : Test rapide des modules\n",
    "\n",
    "Testons rapidement chaque composant principal du syst√®me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39b711",
   "metadata": {
    "id": "7a39b711"
   },
   "outputs": [],
   "source": [
    "# Test rapide de chaque composant\n",
    "print(\"=\" * 60)\n",
    "print(\"üß™ TESTS DES COMPOSANTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Test 1: Configuration\n",
    "print(\"\\n1Ô∏è‚É£  Test de chargement de la configuration...\")\n",
    "try:\n",
    "    import yaml\n",
    "    with open('config.yaml', 'r', encoding='utf-8') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "    print(f\"‚úÖ Configuration charg√©e: {len(config)} sections\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur: {e}\")\n",
    "\n",
    "# Test 2: Faster-Whisper (ASR)\n",
    "print(\"\\n2Ô∏è‚É£  Test Faster-Whisper (ASR)...\")\n",
    "try:\n",
    "    from faster_whisper import WhisperModel\n",
    "    # Ne pas charger le mod√®le complet, juste v√©rifier l'import\n",
    "    print(\"‚úÖ Faster-Whisper disponible\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur: {e}\")\n",
    "\n",
    "# Test 3: SentenceTransformers (Embeddings)\n",
    "print(\"\\n3Ô∏è‚É£  Test SentenceTransformers (Embeddings)...\")\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    # Test d'embedding simple\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "    embedding = model.encode(\"Test de phrase\")\n",
    "    print(f\"‚úÖ Embeddings g√©n√©r√©s: dimension {len(embedding)}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur: {e}\")\n",
    "\n",
    "# Test 4: FAISS\n",
    "print(\"\\n4Ô∏è‚É£  Test FAISS (Index vectoriel)...\")\n",
    "try:\n",
    "    import faiss\n",
    "    import numpy as np\n",
    "    # Cr√©er un petit index de test\n",
    "    dimension = 384\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    vectors = np.random.random((10, dimension)).astype('float32')\n",
    "    index.add(vectors)\n",
    "    print(f\"‚úÖ FAISS op√©rationnel: {index.ntotal} vecteurs index√©s\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur: {e}\")\n",
    "\n",
    "# Test 5: llama-cpp-python\n",
    "print(\"\\n5Ô∏è‚É£  Test llama-cpp-python (LLM)...\")\n",
    "try:\n",
    "    from llama_cpp import Llama\n",
    "    print(\"‚úÖ llama-cpp-python disponible\")\n",
    "    # V√©rifier si CUDA est support√©\n",
    "    import llama_cpp\n",
    "    print(f\"   Version: {llama_cpp.__version__ if hasattr(llama_cpp, '__version__') else 'N/A'}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur: {e}\")\n",
    "\n",
    "# Test 6: Gradio\n",
    "print(\"\\n6Ô∏è‚É£  Test Gradio (UI)...\")\n",
    "try:\n",
    "    import gradio as gr\n",
    "    print(f\"‚úÖ Gradio {gr.__version__} disponible\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Erreur: {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"‚úÖ Tests de base termin√©s!\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nüí° Conseil: Vous pouvez maintenant utiliser les modules du projet.\")\n",
    "print(\"   - Construire un indice RAG: python -m src.rag_build\")\n",
    "print(\"   - Lancer l'UI: python ui/app.py\")\n",
    "print(\"   - D√©mo CLI: python demo_cli.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a1f087d",
   "metadata": {
    "id": "8a1f087d"
   },
   "source": [
    "## üéâ Installation termin√©e !\n",
    "\n",
    "Votre environnement Agent Vocal IA est pr√™t. Vous pouvez maintenant :\n",
    "\n",
    "1. **Construire des indices RAG** pour vos mati√®res\n",
    "2. **Tester les modules individuellement** (ASR, TTS, LLM)\n",
    "3. **Lancer l'interface Gradio** pour une utilisation interactive\n",
    "4. **Utiliser le mode CLI** pour des tests en ligne de commande\n",
    "\n",
    "### Prochaines √©tapes\n",
    "\n",
    "Consultez le `README.md` pour les instructions d'utilisation d√©taill√©es."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}