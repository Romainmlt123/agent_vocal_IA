{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Vocal IA - Environment Sanity Check\n",
    "\n",
    "This notebook verifies that all dependencies and components are properly installed for the Agent Vocal IA project.\n",
    "\n",
    "## Components to Check:\n",
    "1. Python version (3.10)\n",
    "2. GPU availability (CUDA)\n",
    "3. Core dependencies\n",
    "4. Model files\n",
    "5. Data directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Python Version Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Version info: {sys.version_info}\")\n",
    "\n",
    "assert sys.version_info >= (3, 10), \"Python 3.10 or higher required!\"\n",
    "print(\"✓ Python version OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. GPU/CUDA Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
    "    print(\"✓ GPU available\")\n",
    "else:\n",
    "    print(\"⚠ GPU not available - will use CPU (slower)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Core Dependencies Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check ASR dependencies\n",
    "try:\n",
    "    from faster_whisper import WhisperModel\n",
    "    print(\"✓ faster-whisper installed\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ faster-whisper not installed: {e}\")\n",
    "\n",
    "# Check RAG dependencies\n",
    "try:\n",
    "    import faiss\n",
    "    print(f\"✓ FAISS installed (version: {faiss.__version__})\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ FAISS not installed: {e}\")\n",
    "\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    print(\"✓ SentenceTransformers installed\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ SentenceTransformers not installed: {e}\")\n",
    "\n",
    "# Check LLM dependencies\n",
    "try:\n",
    "    from llama_cpp import Llama\n",
    "    print(\"✓ llama-cpp-python installed\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ llama-cpp-python not installed: {e}\")\n",
    "\n",
    "# Check TTS dependencies\n",
    "try:\n",
    "    import subprocess\n",
    "    result = subprocess.run(['piper', '--version'], capture_output=True, text=True)\n",
    "    print(f\"✓ piper-tts installed\")\n",
    "except FileNotFoundError:\n",
    "    print(\"⚠ piper-tts command not found in PATH\")\n",
    "\n",
    "# Check utility dependencies\n",
    "try:\n",
    "    import numpy as np\n",
    "    print(f\"✓ NumPy installed (version: {np.__version__})\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ NumPy not installed: {e}\")\n",
    "\n",
    "try:\n",
    "    import soundfile as sf\n",
    "    print(\"✓ soundfile installed\")\n",
    "except ImportError as e:\n",
    "    print(f\"✗ soundfile not installed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Project Structure Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Expected directories\n",
    "expected_dirs = [\n",
    "    'src',\n",
    "    'data/maths',\n",
    "    'data/physique',\n",
    "    'data/anglais',\n",
    "    'models/llm',\n",
    "    'models/voices',\n",
    "    'ui'\n",
    "]\n",
    "\n",
    "print(\"Checking project structure...\")\n",
    "for directory in expected_dirs:\n",
    "    if os.path.exists(directory):\n",
    "        print(f\"✓ {directory}/\")\n",
    "    else:\n",
    "        print(f\"✗ {directory}/ (missing)\")\n",
    "\n",
    "# Check for key files\n",
    "expected_files = [\n",
    "    'requirements.txt',\n",
    "    'demo_cli.py',\n",
    "    'README.md',\n",
    "    'src/__init__.py',\n",
    "    'src/asr.py',\n",
    "    'src/rag.py',\n",
    "    'src/llm.py',\n",
    "    'src/tts.py',\n",
    "    'src/pipeline.py'\n",
    "]\n",
    "\n",
    "print(\"\\nChecking key files...\")\n",
    "for file in expected_files:\n",
    "    if os.path.exists(file):\n",
    "        print(f\"✓ {file}\")\n",
    "    else:\n",
    "        print(f\"✗ {file} (missing)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model Files Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"Checking for model files...\\n\")\n",
    "\n",
    "# Check LLM models\n",
    "llm_dir = Path('models/llm')\n",
    "llm_models = list(llm_dir.glob('*.gguf')) if llm_dir.exists() else []\n",
    "if llm_models:\n",
    "    print(\"✓ LLM models found:\")\n",
    "    for model in llm_models:\n",
    "        size = model.stat().st_size / (1024**3)  # Convert to GB\n",
    "        print(f\"  - {model.name} ({size:.2f} GB)\")\n",
    "else:\n",
    "    print(\"⚠ No LLM models found in models/llm/\")\n",
    "    print(\"  Download a GGUF model (e.g., from HuggingFace)\")\n",
    "\n",
    "# Check TTS voices\n",
    "voices_dir = Path('models/voices')\n",
    "voice_models = list(voices_dir.glob('*.onnx')) if voices_dir.exists() else []\n",
    "if voice_models:\n",
    "    print(\"\\n✓ TTS voice models found:\")\n",
    "    for model in voice_models:\n",
    "        print(f\"  - {model.name}\")\n",
    "else:\n",
    "    print(\"\\n⚠ No TTS voice models found in models/voices/\")\n",
    "    print(\"  Download Piper voice models from: https://github.com/rhasspy/piper/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test Import of Custom Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'src')\n",
    "\n",
    "try:\n",
    "    from src import asr, rag, llm, tts, pipeline\n",
    "    print(\"✓ All custom modules imported successfully\")\n",
    "    print(f\"  - ASR module: {asr.__name__}\")\n",
    "    print(f\"  - RAG module: {rag.__name__}\")\n",
    "    print(f\"  - LLM module: {llm.__name__}\")\n",
    "    print(f\"  - TTS module: {tts.__name__}\")\n",
    "    print(f\"  - Pipeline module: {pipeline.__name__}\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error importing custom modules: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Quick Integration Test (Optional)\n",
    "\n",
    "This cell tests basic functionality if models are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SentenceTransformer encoding\n",
    "try:\n",
    "    from sentence_transformers import SentenceTransformer\n",
    "    \n",
    "    print(\"Testing SentenceTransformer encoding...\")\n",
    "    encoder = SentenceTransformer('paraphrase-multilingual-mpnet-base-v2')\n",
    "    test_text = \"Qu'est-ce que la gravité?\"\n",
    "    embedding = encoder.encode([test_text])\n",
    "    print(f\"✓ Embedding shape: {embedding.shape}\")\n",
    "    print(f\"✓ SentenceTransformer working correctly\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠ SentenceTransformer test failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Run all cells above to verify your environment. If any checks fail:\n",
    "\n",
    "1. **Missing dependencies**: Run `pip install -r requirements.txt`\n",
    "2. **Missing models**: Download required models (LLM GGUF, TTS ONNX)\n",
    "3. **GPU issues**: Check CUDA installation and drivers\n",
    "\n",
    "For Colab users:\n",
    "- Make sure you're using a GPU runtime (Runtime → Change runtime type → GPU)\n",
    "- Models will be downloaded on first use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "Once environment checks pass:\n",
    "1. Add your course materials to `data/maths/`, `data/physique/`, `data/anglais/`\n",
    "2. Download a GGUF model to `models/llm/`\n",
    "3. Download Piper voice models to `models/voices/`\n",
    "4. Run `python demo_cli.py --index` to index your documents\n",
    "5. Start using the tutor with `python demo_cli.py --mode text`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
