{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì Agent Vocal IA - Setup Colab\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT** : Activez le GPU ‚Üí Runtime ‚Üí Change runtime type ‚Üí T4 GPU ‚Üí Save\n",
    "\n",
    "Installation optimis√©e pour Python 3.12+ avec gestion automatique des erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã √âtape 1 : V√©rification GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys, platform\n",
    "print(\"=\" * 60)\n",
    "print(f\"üñ•Ô∏è  Python {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "print(\"=\" * 60)\n",
    "try:\n",
    "    subprocess.run(['nvidia-smi'], check=True, capture_output=True)\n",
    "    print(\"‚úÖ GPU d√©tect√©!\")\n",
    "except:\n",
    "    print(\"‚ö†Ô∏è  Aucun GPU - Activez-le: Runtime ‚Üí Change runtime type ‚Üí T4 GPU\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• √âtape 2 : Clonage du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "if os.path.exists('agent_vocal_IA'):\n",
    "    shutil.rmtree('agent_vocal_IA')\n",
    "!git clone https://github.com/Romainmlt123/agent_vocal_IA.git\n",
    "%cd agent_vocal_IA\n",
    "print(f\"‚úÖ Projet clon√©: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì¶ √âtape 3 : Installation (5-10 min)\n",
    "\n",
    "**R√©sout automatiquement** :\n",
    "- ‚úÖ PortAudio (sounddevice)\n",
    "- ‚úÖ NumPy <2.0 (compatibilit√©)\n",
    "- ‚úÖ FAISS-GPU ‚Üí FAISS-CPU\n",
    "- ‚úÖ llama-cpp-python CUDA\n",
    "- ‚úÖ gTTS (Piper incompatible Python 3.12+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installation robuste pour Colab Python 3.12+\n",
    "print(\"üîÑ Installation...\")\n",
    "print()\n",
    "\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "# √âtape 1 : PortAudio\n",
    "print(\"1/8 PortAudio...\")\n",
    "!apt-get update -qq > /dev/null 2>&1\n",
    "!apt-get install -qq -y portaudio19-dev > /dev/null 2>&1\n",
    "\n",
    "# √âtape 2 : Packages de base\n",
    "print(\"2/8 Packages base...\")\n",
    "!pip install -q torch>=2.0.0 torchaudio>=2.0.0 faster-whisper==1.0.3 sentence-transformers==2.7.0 pypdf==4.2.0 langchain==0.2.11 langchain-community==0.2.10 gradio>=4.44.0\n",
    "\n",
    "# √âtape 3 : NumPy - D√âSINSTALLER packages conflictuels puis r√©installer\n",
    "print(\"3/8 NumPy...\")\n",
    "!pip uninstall -y -q opencv-python opencv-python-headless opencv-contrib-python jax jaxlib pytensor thinc 2>/dev/null\n",
    "!pip install -q 'numpy>=1.24,<2.0'\n",
    "# R√©installer opencv compatible\n",
    "!pip install -q 'opencv-python-headless>=4.5,<4.10'\n",
    "\n",
    "# √âtape 4 : Audio\n",
    "print(\"4/8 Audio...\")\n",
    "!pip install -q pyyaml>=6.0.2 soundfile sounddevice\n",
    "\n",
    "# √âtape 5 : FAISS\n",
    "print(\"5/8 FAISS...\")\n",
    "result = subprocess.run(['pip', 'install', '-q', 'faiss-gpu'], capture_output=True, text=True)\n",
    "if result.returncode != 0:\n",
    "    !pip install -q faiss-cpu==1.8.0\n",
    "\n",
    "# √âtape 6 : Silero VAD\n",
    "print(\"6/8 Silero VAD...\")\n",
    "!pip install -q silero-vad\n",
    "\n",
    "# √âtape 7 : llama-cpp-python\n",
    "print(\"7/8 llama-cpp-python...\")\n",
    "result = subprocess.run(\n",
    "    ['pip', 'install', '-q', 'llama-cpp-python', '--extra-index-url',\n",
    "     'https://abetlen.github.io/llama-cpp-python/whl/cu121'],\n",
    "    capture_output=True, text=True\n",
    ")\n",
    "if result.returncode != 0:\n",
    "    !pip install -q llama-cpp-python\n",
    "\n",
    "# √âtape 8 : TTS\n",
    "print(\"8/8 TTS...\")\n",
    "!pip install -q gTTS pyttsx3\n",
    "\n",
    "print()\n",
    "print(\"‚úÖ Installation termin√©e!\")\n",
    "print(\"üìù TTS: gTTS install√© (Piper incompatible Python 3.12+)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚úÖ √âtape 4 : V√©rification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìö V√©rification...\\n\")\n",
    "modules = ['torch','faster_whisper','sentence_transformers','faiss','langchain','llama_cpp','gradio','numpy','sounddevice','gtts']\n",
    "ok = 0\n",
    "for m in modules:\n",
    "    try:\n",
    "        __import__(m.replace('-','_'))\n",
    "        print(f\"‚úÖ {m}\")\n",
    "        ok += 1\n",
    "    except:\n",
    "        print(f\"‚ùå {m}\")\n",
    "print(f\"\\nüìä {ok}/{len(modules)} modules OK\")\n",
    "print(\"üéâ Pr√™t!\" if ok >= len(modules)-1 else \"‚ö†Ô∏è  R√©ex√©cutez l'installation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üì• √âtape 5 : T√©l√©chargement mod√®le LLM (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"models/llm\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "url = \"https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf\"\n",
    "dest = \"models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf\"\n",
    "\n",
    "if os.path.exists(dest):\n",
    "    print(\"‚úÖ Mod√®le d√©j√† t√©l√©charg√©\")\n",
    "else:\n",
    "    print(\"üì• T√©l√©chargement Phi-3 Mini (2.4 GB)...\")\n",
    "    def progress(b, bs, t):\n",
    "        p = min(100, b*bs*100/t) if t > 0 else 0\n",
    "        print(f\"\\r[{'‚ñà'*int(p/2.5)}{'‚ñë'*(40-int(p/2.5))}] {p:.1f}%\", end='')\n",
    "    urllib.request.urlretrieve(url, dest, progress)\n",
    "    print(\"\\n‚úÖ T√©l√©charg√©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîç √âtape 6 : Construction indices RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Construction des indices RAG...\\n\")\n",
    "!python -m src.rag_build --subject maths\n",
    "!python -m src.rag_build --subject physique\n",
    "!python -m src.rag_build --subject anglais\n",
    "print(\"\\n‚úÖ Indices construits!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ √âtape 7 : Lancement interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ui.app import launch_ui\n",
    "print(\"üöÄ Lancement...\\n\")\n",
    "launch_ui(share=True)\n",
    "print(\"\\nüìù Cliquez sur le lien ci-dessus\")\n",
    "print(\"‚ö†Ô∏è  Utilisez le mode TEXTE (TTS pas disponible sur Python 3.12+)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}