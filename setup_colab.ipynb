{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“ Agent Vocal IA - Setup Colab\n",
    "\n",
    "**âš ï¸ IMPORTANT** : Activez le GPU â†’ Runtime â†’ Change runtime type â†’ T4 GPU â†’ Save\n",
    "\n",
    "Installation optimisÃ©e pour Python 3.12+ avec gestion automatique des erreurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ Ã‰tape 1 : VÃ©rification GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys, platform\n",
    "print(\"=\" * 60)\n",
    "print(f\"ğŸ–¥ï¸  Python {sys.version_info.major}.{sys.version_info.minor}.{sys.version_info.micro}\")\n",
    "print(\"=\" * 60)\n",
    "try:\n",
    "    subprocess.run(['nvidia-smi'], check=True, capture_output=True)\n",
    "    print(\"âœ… GPU dÃ©tectÃ©!\")\n",
    "except:\n",
    "    print(\"âš ï¸  Aucun GPU - Activez-le: Runtime â†’ Change runtime type â†’ T4 GPU\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Ã‰tape 2 : Clonage du projet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "if os.path.exists('agent_vocal_IA'):\n",
    "    shutil.rmtree('agent_vocal_IA')\n",
    "!git clone https://github.com/Romainmlt123/agent_vocal_IA.git\n",
    "%cd agent_vocal_IA\n",
    "print(f\"âœ… Projet clonÃ©: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¦ Ã‰tape 3 : Installation (5-10 min)\n",
    "\n",
    "**RÃ©sout automatiquement** :\n",
    "- âœ… PortAudio (sounddevice)\n",
    "- âœ… NumPy <2.0 (compatibilitÃ©)\n",
    "- âœ… FAISS-GPU â†’ FAISS-CPU\n",
    "- âœ… llama-cpp-python CUDA\n",
    "- âœ… gTTS (Piper incompatible Python 3.12+)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, subprocess\n",
    "print(\"ğŸ”„ Installation...\")\n",
    "\n",
    "# 1. PortAudio\n",
    "print(\"\\n1/8 PortAudio...\")\n",
    "!apt-get update -qq && apt-get install -qq -y portaudio19-dev > /dev/null 2>&1\n",
    "\n",
    "# 2. Packages base\n",
    "print(\"2/8 Packages base...\")\n",
    "!pip install -q torch torchaudio faster-whisper==1.0.3 sentence-transformers==2.7.0\n",
    "!pip install -q pypdf==4.2.0 langchain==0.2.11 langchain-community==0.2.10 gradio==4.36.1\n",
    "\n",
    "# 3. NumPy\n",
    "print(\"3/8 NumPy...\")\n",
    "!pip install -q 'numpy>=1.24,<2.0'\n",
    "\n",
    "# 4. Audio\n",
    "print(\"4/8 Audio...\")\n",
    "!pip install -q pyyaml soundfile sounddevice\n",
    "\n",
    "# 5. FAISS\n",
    "print(\"5/8 FAISS...\")\n",
    "if subprocess.run(['pip','install','-q','faiss-gpu'], capture_output=True).returncode != 0:\n",
    "    !pip install -q faiss-cpu==1.8.0\n",
    "\n",
    "# 6. Silero VAD\n",
    "print(\"6/8 Silero VAD...\")\n",
    "!pip install -q silero-vad\n",
    "\n",
    "# 7. llama-cpp-python\n",
    "print(\"7/8 llama-cpp-python...\")\n",
    "if subprocess.run(['pip','install','-q','llama-cpp-python','--extra-index-url','https://abetlen.github.io/llama-cpp-python/whl/cu121'], capture_output=True).returncode != 0:\n",
    "    !pip install -q llama-cpp-python==0.2.85\n",
    "\n",
    "# 8. TTS\n",
    "print(\"8/8 TTS...\")\n",
    "!pip install -q gTTS pyttsx3\n",
    "\n",
    "print(\"\\nâœ… Installation terminÃ©e!\")\n",
    "print(\"ğŸ“ TTS: gTTS installÃ© (Piper incompatible Python 3.12+)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ… Ã‰tape 4 : VÃ©rification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ“š VÃ©rification...\\n\")\n",
    "modules = ['torch','faster_whisper','sentence_transformers','faiss','langchain','llama_cpp','gradio','numpy','sounddevice','gtts']\n",
    "ok = 0\n",
    "for m in modules:\n",
    "    try:\n",
    "        __import__(m.replace('-','_'))\n",
    "        print(f\"âœ… {m}\")\n",
    "        ok += 1\n",
    "    except:\n",
    "        print(f\"âŒ {m}\")\n",
    "print(f\"\\nğŸ“Š {ok}/{len(modules)} modules OK\")\n",
    "print(\"ğŸ‰ PrÃªt!\" if ok >= len(modules)-1 else \"âš ï¸  RÃ©exÃ©cutez l'installation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“¥ Ã‰tape 5 : TÃ©lÃ©chargement modÃ¨le LLM (10 min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, urllib.request\n",
    "from pathlib import Path\n",
    "\n",
    "Path(\"models/llm\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "url = \"https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf\"\n",
    "dest = \"models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf\"\n",
    "\n",
    "if os.path.exists(dest):\n",
    "    print(\"âœ… ModÃ¨le dÃ©jÃ  tÃ©lÃ©chargÃ©\")\n",
    "else:\n",
    "    print(\"ğŸ“¥ TÃ©lÃ©chargement Phi-3 Mini (2.4 GB)...\")\n",
    "    def progress(b, bs, t):\n",
    "        p = min(100, b*bs*100/t) if t > 0 else 0\n",
    "        print(f\"\\r[{'â–ˆ'*int(p/2.5)}{'â–‘'*(40-int(p/2.5))}] {p:.1f}%\", end='')\n",
    "    urllib.request.urlretrieve(url, dest, progress)\n",
    "    print(\"\\nâœ… TÃ©lÃ©chargÃ©!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Ã‰tape 6 : Construction indices RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ğŸ” Construction des indices RAG...\\n\")\n",
    "!python -m src.rag_build --subject maths\n",
    "!python -m src.rag_build --subject physique\n",
    "!python -m src.rag_build --subject anglais\n",
    "print(\"\\nâœ… Indices construits!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸš€ Ã‰tape 7 : Lancement interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ui.app import launch_ui\n",
    "print(\"ğŸš€ Lancement...\\n\")\n",
    "launch_ui(share=True)\n",
    "print(\"\\nğŸ“ Cliquez sur le lien ci-dessus\")\n",
    "print(\"âš ï¸  Utilisez le mode TEXTE (TTS pas disponible sur Python 3.12+)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"},
  "language_info": {"name": "python", "version": "3.12.0"}
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
