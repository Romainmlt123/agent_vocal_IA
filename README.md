# ğŸ“ Agent Vocal IA - Tuteur Ã‰ducatif Local

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Romainmlt123/agent_vocal_IA/blob/main/setup_colab.ipynb)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)

Un assistant vocal Ã©ducatif **100% local** pour l'apprentissage interactif. ConÃ§u pour Google Colab (GPU T4/A100), sans aucune dÃ©pendance Ã  des APIs externes.

**ğŸ¤ Parlez Ã  votre IA - Elle vous rÃ©pond vocalement avec des indices progressifs !**

---

## ğŸ¯ Objectif

CrÃ©er un tuteur vocal IA capable de :

- ğŸ¤ **Ã‰couter** : L'utilisateur parle (franÃ§ais ou anglais) â†’ Transcription vocale avec Faster-Whisper
- ğŸ” **Chercher** : RÃ©cupÃ©ration d'informations pertinentes via RAG (FAISS + SentenceTransformers)
- ğŸ§  **Raisonner** : GÃ©nÃ©ration de rÃ©ponses pÃ©dagogiques avec LLM local (Phi-3 Mini)
- ğŸ”Š **Parler** : RÃ©ponse vocale avec Piper-TTS
- ğŸ’¡ **Guider** : Fournir 3 niveaux d'indices progressifs sans jamais donner la solution complÃ¨te

### MatiÃ¨res SupportÃ©es
- ğŸ“ **MathÃ©matiques** : AlgÃ¨bre, gÃ©omÃ©trie, calcul
- âš¡ **Physique** : MÃ©canique, Ã©lectricitÃ©, Ã©nergie
- ğŸ‡¬ğŸ‡§ **Anglais** : Grammaire, vocabulaire, traduction

---

## âœ¨ FonctionnalitÃ©s

### ğŸ¤ Modes d'Interaction

#### 1. **Mode Conversation Continue** (RecommandÃ©)
- Cliquez une fois pour dÃ©marrer
- Parlez naturellement autant que vous voulez
- DÃ©tection automatique de fin de parole (VAD)
- L'IA rÃ©pond vocalement aprÃ¨s chaque question
- Cliquez pour arrÃªter quand vous avez fini

#### 2. **Mode Vocal Manuel**
- Cliquez pour commencer l'enregistrement
- Parlez votre question
- Cliquez pour arrÃªter
- L'IA traite et rÃ©pond

#### 3. **Mode Texte**
- Tapez votre question
- Option de gÃ©nÃ©ration vocale de la rÃ©ponse

### ğŸ§  SystÃ¨me d'Indices Progressifs

L'IA ne donne **jamais** la solution complÃ¨te. Elle guide avec 3 niveaux :

**Exemple : "RÃ©soudre xÂ² - 4 = 0"**

```
Indice 1 (LÃ©ger) : "As-tu pensÃ© Ã  la factorisation ?"
Indice 2 (Moyen) : "C'est une diffÃ©rence de carrÃ©s : aÂ² - bÂ²"
Indice 3 (Fort) : "Factorise en (x-2)(x+2) = 0, puis applique le produit nul"
```

L'Ã©lÃ¨ve doit trouver : **x = 2 ou x = -2**

---

## ğŸš€ Installation sur Google Colab

### Option 1 : Installation Automatique (RecommandÃ©e)

1. **Cliquez sur le badge** â†’ [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Romainmlt123/agent_vocal_IA/blob/main/setup_colab.ipynb)

2. **Activez le GPU** :
   - Menu "ExÃ©cution" â†’ "Modifier le type d'exÃ©cution"
   - SÃ©lectionnez "T4 GPU" ou "A100 GPU"
   - Cliquez "Enregistrer"

3. **ExÃ©cutez toutes les cellules** :
   - Menu "ExÃ©cution" â†’ "Tout exÃ©cuter"
   - Attendez ~10-15 minutes (installation + tÃ©lÃ©chargement des modÃ¨les)

4. **Lancez l'interface** :
   - Un lien public Gradio s'affichera : `https://xxxxx.gradio.live`
   - Cliquez dessus pour ouvrir l'interface

5. **Commencez Ã  parler** ! ğŸ¤

### Option 2 : Installation Manuelle

```python
# Cellule 1 : VÃ©rifier le GPU
!nvidia-smi

# Cellule 2 : Cloner le projet
!git clone https://github.com/Romainmlt123/agent_vocal_IA.git
%cd agent_vocal_IA

# Cellule 3 : Installer les dÃ©pendances
!pip install -q -r requirements.txt
!pip install -q faiss-gpu
!CMAKE_ARGS="-DLLAMA_CUBLAS=on" pip install -q llama-cpp-python --upgrade --force-reinstall --no-cache-dir

# Cellule 4 : TÃ©lÃ©charger les modÃ¨les IA
!mkdir -p models/llm models/voices

# LLM : Phi-3 Mini 4K Instruct (2.4 GB)
!wget -q --show-progress -P models/llm/ \
  https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-q4.gguf

# TTS : Voix franÃ§aise Piper (60 MB)
!wget -q --show-progress -P models/voices/ \
  https://huggingface.co/rhasspy/piper-voices/resolve/main/fr/fr_FR/siwis/medium/fr_FR-siwis-medium.onnx
!wget -q --show-progress -P models/voices/ \
  https://huggingface.co/rhasspy/piper-voices/resolve/main/fr/fr_FR/siwis/medium/fr_FR-siwis-medium.onnx.json

# Cellule 5 : Construire les indices RAG
!python -m src.rag_build --subject maths
!python -m src.rag_build --subject physique
!python -m src.rag_build --subject anglais

# Cellule 6 : Lancer l'interface
from ui.app import launch_ui
launch_ui(share=True)
```

---

## ğŸ’» Utilisation

### Interface Gradio (Mode Principal)

Une fois l'interface lancÃ©e :

1. **Autorisez le microphone** dans votre navigateur
2. **SÃ©lectionnez une matiÃ¨re** ou laissez la dÃ©tection automatique
3. **Choisissez votre mode** :

#### Mode Conversation Continue ğŸ’¬
```
1. Cliquez "ğŸ¤ DÃ©marrer la conversation"
2. Parlez : "Comment rÃ©soudre une Ã©quation du second degrÃ© ?"
3. Attendez 1 seconde (le VAD dÃ©tecte automatiquement la fin)
4. Ã‰coutez la rÃ©ponse vocale (~20 secondes de traitement)
5. Continuez Ã  parler sans recliquer !
6. Cliquez "ğŸ›‘ ArrÃªter" quand vous avez fini
```

#### Mode Vocal Manuel ğŸ¤
```
1. Cliquez sur le bouton micro
2. Parlez votre question
3. Cliquez Ã  nouveau pour arrÃªter
4. Ã‰coutez la rÃ©ponse
```

#### Mode Texte ğŸ’¬
```
1. Tapez votre question
2. Activez "GÃ©nÃ©rer l'audio" si vous voulez la voix
3. Cliquez "Envoyer"
4. Lisez/Ã©coutez la rÃ©ponse
```

### CLI (Ligne de Commande)

```bash
# Mode interactif
python demo_cli.py --interactive

# Mode texte simple
python demo_cli.py --text "Explique-moi le thÃ©orÃ¨me de Pythagore"

# Mode audio avec fichier
python demo_cli.py --audio question.wav --subject maths
```

---

## ğŸ—ï¸ Architecture

```
agent_vocal_IA/
â”œâ”€â”€ README.md                    # Ce fichier
â”œâ”€â”€ CHANGELOG.md                 # Historique des modifications
â”œâ”€â”€ requirements.txt             # DÃ©pendances Python
â”œâ”€â”€ config.yaml                  # Configuration centralisÃ©e
â”œâ”€â”€ setup_colab.ipynb            # Installation automatique Colab
â”œâ”€â”€ demo_cli.py                  # Interface CLI
â”‚
â”œâ”€â”€ src/                         # Code source principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ utils.py                 # Utilitaires (Config, logging)
â”‚   â”œâ”€â”€ asr.py                   # Reconnaissance vocale (Faster-Whisper + VAD)
â”‚   â”œâ”€â”€ rag_build.py             # Construction des indices RAG
â”‚   â”œâ”€â”€ rag.py                   # Recherche RAG (FAISS)
â”‚   â”œâ”€â”€ llm.py                   # GÃ©nÃ©ration LLM (Phi-3 Mini)
â”‚   â”œâ”€â”€ tts.py                   # SynthÃ¨se vocale (Piper-TTS)
â”‚   â”œâ”€â”€ orchestrator.py          # Pipeline complet ASRâ†’RAGâ†’LLMâ†’TTS
â”‚   â””â”€â”€ conversation_manager.py  # Gestion conversation continue avec VAD
â”‚
â”œâ”€â”€ ui/                          # Interface utilisateur
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ app.py                   # Interface Gradio
â”‚
â”œâ”€â”€ data/                        # DonnÃ©es Ã©ducatives
â”‚   â”œâ”€â”€ maths/                   # Cours de mathÃ©matiques
â”‚   â”œâ”€â”€ physique/                # Cours de physique
â”‚   â”œâ”€â”€ anglais/                 # Cours d'anglais
â”‚   â””â”€â”€ indices/                 # Indices FAISS (gÃ©nÃ©rÃ©s)
â”‚
â”œâ”€â”€ models/                      # ModÃ¨les IA (tÃ©lÃ©chargÃ©s)
â”‚   â”œâ”€â”€ llm/                     # Phi-3 Mini GGUF (~2.4 GB)
â”‚   â””â”€â”€ voices/                  # Voix Piper ONNX (~60 MB)
â”‚
â”œâ”€â”€ outputs/                     # Sorties gÃ©nÃ©rÃ©es
â”‚   â””â”€â”€ audio/                   # Fichiers audio TTS
â”‚
â””â”€â”€ tests/                       # Tests unitaires
    â”œâ”€â”€ test_utils.py
    â”œâ”€â”€ test_rag.py
    â””â”€â”€ test_integration.py
```

---

## âš™ï¸ Configuration

Tous les paramÃ¨tres sont dans `config.yaml` :

### ASR (Reconnaissance Vocale)
```yaml
asr:
  model_name: "small"          # tiny, base, small, medium, large
  language: "fr"               # FranÃ§ais par dÃ©faut
  device: "cuda"               # GPU si disponible
  compute_type: "float16"      # int8, float16, float32
  vad_enabled: true
```

### RAG (Retrieval Augmented Generation)
```yaml
rag:
  embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  chunk_size: 512
  chunk_overlap: 50
  top_k: 3                     # Nombre de documents rÃ©cupÃ©rÃ©s
```

### LLM (ModÃ¨le de Langage)
```yaml
llm:
  model_path: "models/llm/phi-3-mini-4k-instruct.Q4_K_M.gguf"
  n_gpu_layers: 35             # Offloading GPU
  temperature: 0.7
  max_tokens: 512
  progressive_hints: true
  hint_levels: 3
```

### Conversation Continue
```yaml
conversation:
  vad_threshold: 0.5           # Seuil dÃ©tection parole (0-1)
  min_speech_duration_ms: 500  # DurÃ©e min de parole
  min_silence_duration_ms: 800 # Silence pour fin de phrase
```

### TTS (SynthÃ¨se Vocale)
```yaml
tts:
  model_path: "models/voices/fr_FR-siwis-medium.onnx"
  sample_rate: 22050
  speed: 1.0
```

---

## ğŸŒ Support Multilingue

| Composant | FranÃ§ais ğŸ‡«ğŸ‡· | Anglais ğŸ‡¬ğŸ‡§ |
|-----------|--------------|-------------|
| **Ã‰coute (ASR)** | âœ… Oui | âœ… Oui |
| **ComprÃ©hension (LLM)** | âœ… Oui | âœ… Oui |
| **RÃ©ponse Ã©crite** | âœ… Oui | âœ… Oui |
| **Voix (TTS)** | âœ… Oui (native) | âš ï¸ Texte FR uniquement* |

*Pour une voix anglaise, tÃ©lÃ©chargez une voix Piper EN et modifiez `config.yaml`

---

## ğŸ“Š Performances

### Configuration RecommandÃ©e (Google Colab)

| Hardware | GPU T4 (Gratuit) | GPU A100 (Pro) |
|----------|------------------|----------------|
| VRAM | 15 GB | 40 GB |
| CoÃ»t | Gratuit | ~$10/mois |

### Temps de RÃ©ponse

| Ã‰tape | T4 | A100 |
|-------|-----|------|
| Transcription (10s audio) | ~2s | ~1s |
| Recherche RAG | <0.5s | <0.3s |
| GÃ©nÃ©ration LLM (200 tokens) | ~10-15s | ~3-5s |
| SynthÃ¨se vocale | ~1s | ~0.5s |
| **TOTAL par question** | **~15-20s** | **~5-7s** |

**Note** : Le mode conversation continue a un dÃ©lai de traitement aprÃ¨s chaque question, mais l'utilisateur peut enchaÃ®ner plusieurs questions sans recliquer.

---

## ğŸ§ª Tests

```bash
# Tous les tests
pytest tests/ -v

# Tests spÃ©cifiques
pytest tests/test_utils.py -v
pytest tests/test_rag.py -v
pytest tests/test_integration.py -v

# Avec couverture
pytest tests/ --cov=src --cov-report=html
```

---

## ğŸ“ Exemples de Questions

### ğŸ“ MathÃ©matiques
```
"Comment rÃ©soudre xÂ² + 2x - 3 = 0 ?"
"Explique-moi le thÃ©orÃ¨me de Pythagore"
"C'est quoi une dÃ©rivÃ©e ?"
"Comment factoriser une expression ?"
```

### âš¡ Physique
```
"Quelle est la loi de Newton ?"
"Explique-moi la loi d'Ohm"
"DiffÃ©rence entre Ã©nergie cinÃ©tique et potentielle ?"
"Comment calculer une force ?"
```

### ğŸ‡¬ğŸ‡§ Anglais
```
"When do we use the present perfect?"
"Quelle est la diffÃ©rence entre 'do' et 'make' ?"
"Comment conjuguer 'to be' au passÃ© ?"
"Explique-moi les phrasal verbs"
```

---

## ğŸ“š Ajouter Vos Propres Documents

1. **Ajoutez vos fichiers** (PDF ou TXT) dans `data/{matiere}/`
   ```bash
   # Exemple
   cp mes_cours.pdf data/maths/
   ```

2. **Reconstruisez l'indice RAG**
   ```python
   !python -m src.rag_build --subject maths
   ```

3. **L'IA utilisera vos nouveaux documents !**

---

## â“ FAQ

### Le microphone ne fonctionne pas sur Colab

**Solution** : Le micro ne fonctionne PAS dans l'iframe Colab. Utilisez le **lien public Gradio** (`https://xxxxx.gradio.live`) qui s'affiche dans les logs.

### C'est trop lent sur T4

**Normal !** Le GPU T4 gratuit est limitÃ©. Solutions :
- Utilisez un GPU A100 (Colab Pro)
- RÃ©duisez `llm.max_tokens` dans `config.yaml`
- Utilisez le mode texte pour les tests rapides

### Le VAD coupe ma phrase trop tÃ´t

**Ajustez les paramÃ¨tres** dans `config.yaml` :
```yaml
conversation:
  min_silence_duration_ms: 1200  # Au lieu de 800
```

### Comment changer de modÃ¨le LLM ?

1. TÃ©lÃ©chargez un modÃ¨le GGUF depuis [Hugging Face](https://huggingface.co/models?library=gguf)
2. Placez-le dans `models/llm/`
3. Modifiez `config.yaml` :
   ```yaml
   llm:
     model_path: "models/llm/votre-modele.gguf"
   ```

### Le lien Gradio a expirÃ©

Les liens publics expirent aprÃ¨s ~72h. **Relancez simplement** :
```python
from ui.app import launch_ui
launch_ui(share=True)
```

### Erreur "CUDA out of memory"

**RÃ©duisez l'utilisation GPU** dans `config.yaml` :
```yaml
llm:
  n_gpu_layers: 20  # Au lieu de 35
```

Ou **redÃ©marrez le runtime Colab** : Menu "ExÃ©cution" â†’ "RedÃ©marrer la session"

---

## ğŸ”’ Limitations

- **100% local** : NÃ©cessite GPU pour performances acceptables (T4 minimum)
- **Latence** : ~15-20s par question sur T4 (normal pour LLM local)
- **Voix franÃ§aise uniquement** : Pour l'anglais, il faut tÃ©lÃ©charger une voix EN
- **VAD peut couper** : Sur pauses longues (> 800ms), ajustable dans config
- **Pas de streaming transcription** : La transcription apparaÃ®t d'un coup (limitation Faster-Whisper)
- **Connexion Internet** : NÃ©cessaire uniquement pour le tÃ©lÃ©chargement initial des modÃ¨les (~3 GB)

---

## ğŸ¤ Contribution

Les contributions sont les bienvenues !

1. Fork le projet
2. CrÃ©ez une branche (`git checkout -b feature/amelioration`)
3. Committez (`git commit -m 'Ajout fonctionnalitÃ© X'`)
4. Push (`git push origin feature/amelioration`)
5. Ouvrez une Pull Request

### Standards de Code
- Type hints sur toutes les fonctions
- Docstrings (style Google)
- Tests unitaires pour nouvelles fonctionnalitÃ©s
- PEP8 (formatage avec Black)

---

## ğŸ“„ Licence

MIT License - Voir [LICENSE](LICENSE) pour plus de dÃ©tails.

---

## ğŸ™ Remerciements

Merci aux projets open-source :
- [Faster-Whisper](https://github.com/SYSTRAN/faster-whisper) (SYSTRAN)
- [Silero VAD](https://github.com/snakers4/silero-vad)
- [FAISS](https://github.com/facebookresearch/faiss) (Meta)
- [llama.cpp](https://github.com/ggerganov/llama.cpp)
- [llama-cpp-python](https://github.com/abetlen/llama-cpp-python)
- [Piper TTS](https://github.com/rhasspy/piper) (Rhasspy)
- [Gradio](https://www.gradio.app/)
- [Sentence Transformers](https://www.sbert.net/)

---

## ğŸ‘¤ Auteur

**Romain Mallet** - Intelligence Lab  
ğŸ“§ GitHub : [Romainmlt123](https://github.com/Romainmlt123)

---

## ğŸ“ Support

- ğŸ› **Bugs** : [GitHub Issues](https://github.com/Romainmlt123/agent_vocal_IA/issues)
- ğŸ’¬ **Questions** : [GitHub Discussions](https://github.com/Romainmlt123/agent_vocal_IA/discussions)
- ğŸ“– **Documentation** : Ce README + [CHANGELOG.md](CHANGELOG.md)

---

**ğŸ“ Transformez l'apprentissage avec l'IA vocale locale !**
